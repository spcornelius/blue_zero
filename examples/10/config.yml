qnet:
  id: 'dueling'
  depth: 5
  kernel_size: 3
  num_feat: 32
  num_hidden: 64
  bias: true
mode:
  id: 'zero'
  # blank = no normalization of rewards
  reward_norm:
replay:
  capacity: 500_000
  batch_size: 512
  step_diff: 1
training:
  eps_decay_time: 50000
  eps_start: 1.0
  eps_end: 0.05
  gamma: 1.0
  lr: 1.0e-4
  max_epochs: 100000
  max_grad_norm: 1.0
  num_burn_in: 100
  num_play: 100
  play_freq: 100
  optimizer: adamw
  validation_freq: 100
  target_update_mode: soft
  soft_update_rate: 1.0e-5
  hard_update_freq: 1000